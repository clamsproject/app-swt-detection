Model_Name,Label,Accuracy,Precision,Recall,F1-Score
convnextv2_tiny,Overall,0.8010410666465759,0.8010410666465759,0.8010410666465759,0.8010410666465759
convnextv2_tiny,GLOTW,0.672497570514679,0.6865079402923584,0.672497570514679,0.6794305443763733
convnextv2_tiny,CR,0.9313063025474548,0.7809253931045532,0.9313063025474548,0.8495120406150818
convnextv2_tiny,IN,0.9443288445472717,0.8819242119789124,0.9443288445472717,0.9120603203773499
convnextv2_tiny,KU,0.0,0.0,0.0,0.0
convnextv2_tiny,B,1.0,0.9577465057373047,1.0,0.9784172773361206
convnextv2_tiny,S,0.8970588445663452,0.6879699230194092,0.8970588445663452,0.778723418712616
convnextv2_tiny,M,0.0,0.0,0.0,0.0
convnextv2_tiny,Y,0.09615384787321091,0.3571428656578064,0.09615384787321091,0.1515151560306549
convnextv2_tiny,F,0.8023809790611267,0.7985782027244568,0.8023809790611267,0.8004750609397888
convnextv2_tiny,E,0.3253968358039856,0.8039215803146362,0.3253968358039856,0.46327683329582214
convnextv2_tiny,P,0.9488852620124817,0.8238904476165771,0.9488852620124817,0.8819813132286072
convnextv2_tiny,-,0.8547557592391968,0.7497181296348572,0.8547557592391968,0.7987987995147705


Confusion Matrix (cols = preds, rows = golds)
     ,GLOTW,   CR,   IN,   KU,    B,    S,    M,    Y,    F,    E,    P,    -,    +
GLOTW,  692,  166,   20,    0,    0,   71,    0,    2,   57,    5,    3,   13, 1029
   CR,   51,  827,    3,    0,    0,    2,    0,    1,    2,    0,    0,    2,  888
   IN,   11,    7, 1815,    0,    0,    0,    0,    6,    3,   31,   47,    2, 1922
   KU,    2,    9,   26,    0,    0,    0,    0,    9,    6,    0,    1,    2,   55
    B,    0,    0,    0,    0,   68,    0,    0,    0,    0,    0,    0,    0,   68
    S,   12,    3,    0,    0,    3,  183,    0,    0,    3,    0,    0,    0,  204
    M,  136,   12,    3,    0,    0,    5,    0,    0,    4,    0,    0,    2,  162
    Y,   35,   24,    9,    0,    0,    1,    0,   10,    7,    7,    1,   10,  104
    F,   42,    8,    1,    0,    0,    2,    0,    0,  674,    0,   10,  103,  840
    E,   16,    1,  172,    0,    0,    0,    0,    0,   28,  246,  269,   24,  756
    P,    1,    0,    9,    0,    0,    0,    0,    0,    3,   17, 1745,   64, 1839
    -,   10,    2,    0,    0,    0,    2,    0,    0,   57,    0,   42,  665,  778
    +, 1008, 1059, 2058,    0,   71,  266,    0,   28,  844,  306, 2118,  887, 8645


peak-vram-usage,GPU 0 (NVIDIA RTX A6000): 3564.62MB peak; GPU 1 (NVIDIA RTX A6000): 0.00MB peak; GPU 2 (NVIDIA RTX A6000): 0.00MB peak; GPU 3 (NVIDIA RTX A6000): 0.00MB peak
training-time,4915.307152219117
validation-time,45.08787935320288


Epoch 1 loss,1.186159
Epoch 2 loss,0.887498
Epoch 3 loss,0.824353
Epoch 4 loss,0.779159
Epoch 5 loss,0.755910
Epoch 6 loss,0.729669
Epoch 7 loss,0.709835
Epoch 8 loss,0.695434
